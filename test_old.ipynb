{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/export/scratch/Zeren/conda/lib/python3.7/site-packages/pandas/compat/_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.8' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# change the default cache dir so that huggingface won't take the cse space.\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/export/scratch/zeren/KimNLP/HuggingfaceCache/'\n",
    "\n",
    "from utils import save_args, select_activation_fn\n",
    "from old_train import Trainer\n",
    "from old_data import create_data_channels\n",
    "from old_model import BertClassifier\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoModel\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(samples):\n",
    "    samples = list(map(list, zip(*samples)))\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data instance: 805\n",
      "Tokenizing citation contexts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 563/563 [00:00<00:00, 1081.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing citing abstracts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 563/563 [00:00<00:00, 1459.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing cited abstracts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 563/563 [00:00<00:00, 1470.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing citation contexts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 161/161 [00:00<00:00, 1120.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing citing abstracts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 161/161 [00:00<00:00, 1468.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing cited abstracts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 161/161 [00:00<00:00, 1443.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing citation contexts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:00<00:00, 810.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing citing abstracts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:00<00:00, 1558.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing cited abstracts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:00<00:00, 1446.52it/s]\n"
     ]
    }
   ],
   "source": [
    "data_dir = '../../NewData/'\n",
    "data_filename = os.path.join(data_dir, 'old_kim.tsv')\n",
    "model_name = '../../Pre-Trained-SciBERT/checkpoint-213120/'\n",
    "\n",
    "token_train_data, token_val_data, token_test_data = create_data_channels(\n",
    "    data_filename,\n",
    "    model_name,\n",
    "    max_length=512\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(token_test_data, batch_size=1, shuffle=False, collate_fn=collate_fn)\n",
    "dliterator = iter(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = 'Workspaces/test_old_pre_trained_scibert/best_model.pt'\n",
    "model = torch.load(model_filename).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'input_ids': tensor([[  102,   131,   629,   579,  3781,  9942, 30113,   137,  1337,   111,\n",
      "          2923,   467,   111,   158,  1352,   231,  4899,   131,  4211,  8499,\n",
      "           131,   629,   579,  3781,  9942, 30113,   137,   547,  8391,  2168,\n",
      "          7904,   579,  5677,  3212,   205,   121,   238,  1203,   422,   185,\n",
      "           709,   580,  4142, 15688,  3853,   168, 25462,   422,  3526,  1445,\n",
      "          1017,   111,  2220,   131,   238,  2151,   697,   214,  7402,   903,\n",
      "           365,   186,   205,   260,  1107,  1901,   188,   804,   188,  3978,\n",
      "           111,  7246,   131,   238,   527,  1017,   111,  1073,  2501,   191,\n",
      "         25462,   137, 10937,  9320,  3874, 10000,   205,   111,  6226,  8499,\n",
      "           267,  7180,   214,  2271,  3277,  3853,   487,  1135,   579,  2211,\n",
      "          7479,  1352,  2271, 10133,   179,  3098, 11128,   145,  5572,  5803,\n",
      "         30113,   546,   205,   260,  1557,  1901,   355,   131,   111,  3853,\n",
      "           267,  1260,   191,  4039,   487,   111,  5830,   579,  7753,   551,\n",
      "          1815,   214, 30033,   107,   365,   186,   205,   962,  8412,  1530,\n",
      "          1374,   235,   535,  1633,   422,   111,  2257,   377,   241,   705,\n",
      "         27821,   168,  1287,  1409,   235,  2799,  2241,   487,   111,  5242,\n",
      "         30108, 10623,   205,   111,  2271,  3277,  2004,   241,   666,  2728,\n",
      "           168,   158,  3281,   604,   111, 12533, 30108, 10623,   487,   111,\n",
      "         18745,   579,  4559,  1132, 18124, 11545,   205,   111,   429,  4442,\n",
      "           241,  1058,   235,  1795,  5814,   532,  3565,   205,   147,  3782,\n",
      "           111,   907,   131,  1633,   191,   111,  8499,   422,   111,  3853,\n",
      "           267,  2728,   573,  5531,  6223,   263,  1287,   147, 11222, 30131,\n",
      "           231,   205,   111,  2257,  4602,  4795,   267,   152,   412,  6874,\n",
      "          4825,   106,   422,   152,   316,  6874,  1287,   106,   422,   137,\n",
      "           152,   447,  6874,  1012,   106,   190,  7564,  3580,  1245,   121,\n",
      "           111,   412,   579,   137,   447,   145,  5043,   546,   579,  6330,\n",
      "           188,   103]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}] {'input_ids': tensor([[102, 103]]), 'token_type_ids': tensor([[0, 0]]), 'attention_mask': tensor([[1, 1]])} {'input_ids': tensor([[  102,   185,  3138,   111,  2495,   131,   111,  5830,   579,  7753,\n",
      "           551,  1709,  4932, 30119,  3190,  8561,   137,   111,  7806,   579,\n",
      "          2280,  1709,  6226,  3190,   551,   147,  3754, 14767,  8334,   137,\n",
      "          3318,   131,  4580, 21472,  2484,   214,  3841,  4039,   188,   106,\n",
      "           437,  1440,   205,   502,  4932, 30119,  8561,   220,   501,  1530,\n",
      "           205,   482,   165,  4930,   121,   238,   697,   214,   487,   475,\n",
      "          8340,  1496,   506,  7355,   137,  1471,   351, 29440,  8334,   121,\n",
      "           111,  8340,  3139,   205,   111,   494,  1411,   241,  4930,  2049,\n",
      "           487,   106,  3783,  2631,   205,  6722,  4111,   165,  1058,   467,\n",
      "           351, 29440,   422,  6226,   422,   137,  4932, 30119,   545,   168,\n",
      "           111,  8334,   137,  3318,   131,  1323,  4580, 21472,  2484,   131,\n",
      "          4039,   422,   188,   804,   188,   168,  8334,  2252,  8800,  5938,\n",
      "           467,   643,  2484,   205,   185,  5592,   198,   302,   617,  6226,\n",
      "          5403,   563,   469,  4932, 30119,  8561,   300,   195,  4279,   168,\n",
      "          3853,   121,   334,  2996,  8334,   137,  3318,   131,   643,  7479,\n",
      "          8067,   220,  3633,   422,   235,  1823,   168,  4039,   205,   111,\n",
      "         28049,   422,  2177, 13879,   422,   137, 16504,  2484,   131,  4039,\n",
      "           267,  1887,   188,  6845,   385,  9825,   422,   969,   693,   494,\n",
      "          2484,  1709,   139,   205,   159,   205,   422,  5791, 30121,   137,\n",
      "           514, 30114,  3190,   220,  4252,   318,   205,   188,   130,  1836,\n",
      "           131,   238,   669,   422,  4580, 21472,  2484,   131,  3721, 14243,\n",
      "          4039,  7423,   191,  1709,  3641, 30130,  3190,   579,  9077, 26718,\n",
      "           234, 28049,  7195,   220,  2840,   487,   106,  2177,   437,   137,\n",
      "          7753,   928,  3853,   190,   130,  4932, 30119,  1411,   205,   121,\n",
      "          4111,   190,  1798,   453,   422,   111,  1187,   131,   111,  5796,\n",
      "           300,   195,  1676, 23430, 26718,   234, 23430,  5791, 30121,   205,\n",
      "           111, 28049,  1187,  2546,   195, 15442,   214,  3721, 14243,  3342,\n",
      "           205,   103]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]])} [tensor(1)]\n"
     ]
    }
   ],
   "source": [
    "citation_context, citing_abstract, cited_abstract, label = next(dliterator)\n",
    "print(citation_context[0], citing_abstract[0], cited_abstract[0], label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertClassifier(\n",
       "  (hidden_layers): ModuleList(\n",
       "    (0): Linear(in_features=3840, out_features=1024, bias=True)\n",
       "    (1): Linear(in_features=1024, out_features=128, bias=True)\n",
       "    (2): Linear(in_features=128, out_features=8, bias=True)\n",
       "  )\n",
       "  (batch_norm): ModuleList(\n",
       "    (0): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (top_layer): Linear(in_features=8, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (scibert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(31090, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7502,  1.0077]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for i in range(len(citation_context[0])):\n",
    "        citation_context[0][i]['readout_mask'] = None\n",
    "    preds = model(\n",
    "        None,\n",
    "        cited_abstract[0],\n",
    "        None,\n",
    "        citing_abstract[0],\n",
    "        citation_context[0]\n",
    "    )\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for citation_context, citing_abstract, cited_abstract, label in test_loader:\n",
    "        for i in range(len(citation_context[0])):\n",
    "            citation_context[0][i]['readout_mask'] = None\n",
    "        preds.append(model(\n",
    "            None,\n",
    "            cited_abstract[0],\n",
    "            None,\n",
    "            citing_abstract[0],\n",
    "            citation_context[0]\n",
    "        ).detach().cpu().numpy())\n",
    "        labels.append(label)\n",
    "\n",
    "preds = np.concatenate(preds, axis=0)\n",
    "labels = np.concatenate(labels, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.30269256, -0.63129145],\n",
       "        [-0.75021625,  1.0077335 ],\n",
       "        [-0.2956124 ,  0.2644648 ],\n",
       "        [ 0.26255557, -0.4977579 ],\n",
       "        [ 0.3025941 , -0.667239  ],\n",
       "        [-0.5657457 ,  0.7059342 ],\n",
       "        [ 0.2744343 , -0.61456114],\n",
       "        [ 0.21550709, -0.51385987],\n",
       "        [ 0.3190036 , -0.660746  ],\n",
       "        [-0.72832274,  1.0440961 ],\n",
       "        [-0.73572373,  1.0859519 ],\n",
       "        [ 0.30726567, -0.6460807 ],\n",
       "        [ 0.31361094, -0.665917  ],\n",
       "        [-0.7007373 ,  1.0490079 ],\n",
       "        [ 0.30634257, -0.6822105 ],\n",
       "        [ 0.31052265, -0.67988986],\n",
       "        [ 0.30557153, -0.6421743 ],\n",
       "        [-0.71239424,  1.0009856 ],\n",
       "        [-0.15290911,  0.10688871],\n",
       "        [ 0.31224427, -0.67054915],\n",
       "        [-0.6898694 ,  1.0227102 ],\n",
       "        [ 0.29373345, -0.69220215],\n",
       "        [ 0.2731047 , -0.63055223],\n",
       "        [-0.7146323 ,  1.0783947 ],\n",
       "        [-0.6932931 ,  1.0333409 ],\n",
       "        [-0.6335604 ,  0.91107327],\n",
       "        [ 0.28706482, -0.66667753],\n",
       "        [-0.20882446, -0.02140607],\n",
       "        [ 0.3130215 , -0.66073483],\n",
       "        [-0.626819  ,  0.8569595 ],\n",
       "        [-0.70802534,  0.90895844],\n",
       "        [-0.7279632 ,  1.0845095 ],\n",
       "        [-0.7325418 ,  1.0850979 ],\n",
       "        [-0.02876139, -0.26994175],\n",
       "        [ 0.04140362, -0.29381925],\n",
       "        [ 0.28268763, -0.6313398 ],\n",
       "        [ 0.288451  , -0.6601475 ],\n",
       "        [ 0.31133983, -0.6774302 ],\n",
       "        [-0.71329236,  1.0889285 ],\n",
       "        [ 0.2666101 , -0.6575493 ],\n",
       "        [ 0.32230505, -0.62858427],\n",
       "        [ 0.2669371 , -0.60130167],\n",
       "        [ 0.3216438 , -0.66723204],\n",
       "        [ 0.3034688 , -0.66397125],\n",
       "        [ 0.12793759, -0.3900234 ],\n",
       "        [ 0.3110502 , -0.647721  ],\n",
       "        [-0.55991054,  0.5399957 ],\n",
       "        [-0.7070464 ,  1.0326049 ],\n",
       "        [ 0.27143234, -0.5781585 ],\n",
       "        [ 0.28047368, -0.6711779 ],\n",
       "        [ 0.11597708, -0.32301337],\n",
       "        [ 0.32275578, -0.6537654 ],\n",
       "        [-0.1848101 ,  0.07762903],\n",
       "        [ 0.32468   , -0.6225583 ],\n",
       "        [ 0.19761261, -0.45353168],\n",
       "        [ 0.11072865, -0.28562784],\n",
       "        [ 0.297672  , -0.67757064],\n",
       "        [ 0.29422262, -0.67851424],\n",
       "        [-0.01900873, -0.19523166],\n",
       "        [ 0.31757995, -0.6665029 ],\n",
       "        [ 0.29560193, -0.6671883 ],\n",
       "        [ 0.28205183, -0.58439285],\n",
       "        [ 0.27027413, -0.4997735 ],\n",
       "        [ 0.32389006, -0.57819736],\n",
       "        [ 0.33267316, -0.60600525],\n",
       "        [ 0.09666875, -0.301467  ],\n",
       "        [ 0.34420678, -0.62494016],\n",
       "        [ 0.1666885 , -0.40415734],\n",
       "        [ 0.28994772, -0.660275  ],\n",
       "        [-0.72123575,  1.1013287 ],\n",
       "        [-0.7010858 ,  1.0642759 ],\n",
       "        [-0.7078644 ,  1.0663748 ],\n",
       "        [ 0.30773196, -0.6789462 ],\n",
       "        [ 0.30515012, -0.679721  ],\n",
       "        [-0.23358825,  0.13157171],\n",
       "        [ 0.30557755, -0.60163707],\n",
       "        [-0.7422819 ,  1.0790712 ],\n",
       "        [ 0.22622004, -0.5551329 ],\n",
       "        [ 0.3087866 , -0.6692555 ],\n",
       "        [ 0.05369511, -0.27594495]], dtype=float32),\n",
       " array([0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "        0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "        0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7527472527472527"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(labels, preds.argmax(axis=1), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0f2a3cdf9004c2ee13bbc512dd1a2bd0579c3b0699328dd5f9c2b6faa53b53f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
